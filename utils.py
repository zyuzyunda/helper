# app/utils.py

import os
import re
import json
import pdfplumber
import spacy
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity


#numpy==1.26.4

nlp = spacy.load('ru_core_news_md')

# –í–∞–∂–Ω—ã–µ –∫–æ—Ä–æ—Ç–∫–∏–µ –Ω–∞–≤—ã–∫–∏ (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ –∏—Ç–æ–≥—É)
important_short_skills = []


def read_resume_pdf(filepath: str) -> str:
    text = ""
    with pdfplumber.open(filepath) as pdf:
        for page in pdf.pages:
            text += page.extract_text() + "\n"
    return text

def load_skills_json(filepath: str) -> list:
    with open(filepath, 'r', encoding='utf-8') as file:
        skills = json.load(file)
    return skills

def extract_entities_with_skills(text: str, skills_list: list) -> dict:
    doc = nlp(text)
    entities = {'ORG': [], 'DATE': [], 'PERSON': [], 'GPE': [], 'SKILLS': []}

    for ent in doc.ents:
        if ent.label_ in entities:
            entities[ent.label_].append(ent.text.strip())

    lower_text = text.lower()
    for skill in skills_list:
        if skill.lower() in lower_text:
            entities['SKILLS'].append(skill)

    return entities

EMAIL_REG = re.compile(r'[a-z0-9\.\-+_]+@[a-z0-9\.\-+_]+\.[a-z]+')
def extract_emails(resume_text: str) -> list:
    return re.findall(EMAIL_REG, resume_text)

PHONE_REG = re.compile(r'[\+\(]?[1-9][0-9 .\-\(\)]{8,}[0-9]')
def extract_phone_number(resume_text: str) -> str:
    phone = re.findall(PHONE_REG, resume_text)
    if phone:
        number = ''.join(phone[0])
        if len(number) < 16:
            return number
    return None

def estimate_experience_years(text: str) -> int:
    years = re.findall(r'\b(19[8-9]\d|20[0-2]\d|2023|2024)\b', text)
    years = [int(year) for year in years]

    if not years:
        return None

    min_year = min(years)
    max_year = max(years)

    experience = max_year - min_year
    if experience < 0:
        return None
    return experience

def map_experience_to_category(experience_years: int) -> str:
    if experience_years is None:
        return "–ù–µ—Ç –æ–ø—ã—Ç–∞"
    elif experience_years < 1:
        return "–ù–µ—Ç –æ–ø—ã—Ç–∞"
    elif 1 <= experience_years < 3:
        return "1-3 –≥–æ–¥–∞"
    elif 3 <= experience_years <= 6:
        return "–û—Ç 3 –¥–æ 6 –ª–µ—Ç"
    else:
        return "–ë–æ–ª–µ–µ 6 –ª–µ—Ç"

education_keywords = [
    '—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', '–∏–Ω—Å—Ç–∏—Ç—É—Ç', '–∞–∫–∞–¥–µ–º–∏—è', '–∫–æ–ª–ª–µ–¥–∂' 'college',
    'university', 'faculty', '—Ñ–∞–∫—É–ª—å—Ç–µ—Ç'
]
def extract_education(text: str) -> set:
    found_education = set()
    lines = text.lower().split('\n')
    for line in lines:
        for keyword in education_keywords:
            if keyword in line:
                found_education.add(line.strip())
    return found_education

career_keywords = [
    '–∞–Ω–∞–ª–∏—Ç–∏–∫', '–±–∏–∑–Ω–µ—Å-–∞–Ω–∞–ª–∏—Ç–∏–∫', 'data scientist',
    'programmer analyst',  'ml engineer',
    'data engineer', 'data analyst', 'product analyst', 'data science',
    'machine learning engineer', 'data architect', '–ø—Ä–æ–¥—É–∫—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫'
]
def extract_career_titles(text: str) -> set:
    found_titles = set()
    lines = text.lower().split('\n')
    for line in lines:
        for keyword in career_keywords:
            if keyword in line:
                found_titles.add(keyword)
    return found_titles

russian_cities = [
    '–º–æ—Å–∫–≤–∞', '—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥', '–Ω–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫', '–µ–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥', '–∫–∞–∑–∞–Ω—å',
    '–Ω–∏–∂–Ω–∏–π –Ω–æ–≤–≥–æ—Ä–æ–¥', '—á–µ–ª—è–±–∏–Ω—Å–∫', '—Å–∞–º–∞—Ä–∞', '–æ–º—Å–∫', '—Ä–æ—Å—Ç–æ–≤-–Ω–∞-–¥–æ–Ω—É',
    '—É—Ñ–∞', '–∫—Ä–∞—Å–Ω–æ—è—Ä—Å–∫', '–ø–µ—Ä–º—å', '–≤–æ—Ä–æ–Ω–µ–∂', '–≤–æ–ª–≥–æ–≥—Ä–∞–¥', '–∫—Ä–∞—Å–Ω–æ–¥–∞—Ä',
    '—Å–∞—Ä–∞—Ç–æ–≤', '—Ç—é–º–µ–Ω—å', '—Ç–æ–ª—å—è—Ç—Ç–∏', '–∏–∂–µ–≤—Å–∫', '–±–∞—Ä–Ω–∞—É–ª', '—É–ª—å—è–Ω–æ–≤—Å–∫',
    '–∏—Ä–∫—É—Ç—Å–∫', '–≤–ª–∞–¥–∏–≤–æ—Å—Ç–æ–∫', '—è—Ä–æ—Å–ª–∞–≤–ª—å', '–º–∞—Ö–∞—á–∫–∞–ª–∞', '—Ç–æ–º—Å–∫', '–æ—Ä–µ–Ω–±—É—Ä–≥',
    '–∫–µ–º–µ—Ä–æ–≤–æ', '–Ω–æ–≤–æ–∫—É–∑–Ω–µ—Ü–∫', '—Ä—è–∑–∞–Ω—å', '–∞—Å—Ç—Ä–∞—Ö–∞–Ω—å', '–ø–µ–Ω–∑–∞', '–ª–∏–ø–µ—Ü–∫',
    '–∫–∏—Ä–æ–≤', '—á–µ–±–æ–∫—Å–∞—Ä—ã', '—Ç—É–ª–∞', '–∫–∞–ª–∏–Ω–∏–Ω–≥—Ä–∞–¥', '–∫—É—Ä—Å–∫'
]
def extract_locations(text: str) -> set:
    found_cities = set()
    lower_text = text.lower()
    for city in russian_cities:
        if city in lower_text:
            found_cities.add(city)
    return found_cities

def has_photo_in_resume(filepath: str) -> bool:
    with pdfplumber.open(filepath) as pdf:
        if not pdf.pages:
            return False
        first_page = pdf.pages[0]
        if first_page.images:
            return True
    return False

def extract_name(text: str) -> str:
    lines = text.strip().split('\n')
    for line in lines[:5]:
        clean_line = line.strip()
        words = clean_line.split()

        if len(words) in [2, 3]:
            if all(word[0].isupper() for word in words if word.isalpha()):
                if not any(char.isdigit() for char in clean_line) and '@' not in clean_line:
                    return clean_line
    doc = nlp(text)
    for ent in doc.ents:
        if ent.label_ in ('PER', 'PERSON'):
            if len(ent.text.split()) in [2, 3]:
                return ent.text.strip()
    return None

def clean_skills(skills_list: list, skills_dictionary: list) -> list:
    skills_list_lower = [skill.lower().strip() for skill in skills_list]
    skills_dictionary_lower = [skill.lower().strip() for skill in skills_dictionary]
    unique_skills = list(set(skills_list_lower))
    filtered_skills = [skill for skill in unique_skills if skill in skills_dictionary_lower]
    return filtered_skills

def final_clean_skills(skills_list: list, important_short_skills: list = important_short_skills) -> list:
    cleaned = []
    for skill in skills_list:
        if len(skill) > 2 or skill.lower() in important_short_skills:
            if not (skill.isdigit() and skill.lower() not in important_short_skills):
                cleaned.append(skill)
    return cleaned


def extract_experience_category_and_years(text: str) -> tuple:
    pattern = r"–¢—Ä–µ–±—É–µ–º—ã–π –æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã:\s*(.+)"
    match = re.search(pattern, text)

    experience_category = None
    experience_years = None

    if match:
        experience_category = match.group(1).strip()

        # –ò—â–µ–º —á–∏—Å–ª–∞ –≤ –Ω–∞–π–¥–µ–Ω–Ω–æ–π —Å—Ç—Ä–æ–∫–µ
        years = re.findall(r'\d+', experience_category)

        if years:
            # –ë–µ—Ä–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 1 –∏–∑ "1‚Äì3 –≥–æ–¥–∞")
            experience_years = int(years[0])

    return experience_category, experience_years

def process_vacancy(vacancy_text: str, skills_list: list) -> dict:
    career_titles = extract_career_titles(vacancy_text)
    found_locations = extract_locations(vacancy_text)

    extracted_skills = extract_entities_with_skills(vacancy_text, skills_list)
    cleaned_skills = clean_skills(extracted_skills['SKILLS'], skills_list)
    final_skills = final_clean_skills(cleaned_skills)

    experience_category, experience_years = extract_experience_category_and_years(vacancy_text)

    structured_vacancy = {
        "skills": final_skills if final_skills else None,
        "locations": list(found_locations) if found_locations else None,
        "career_titles": list(career_titles) if career_titles else None,
        "experience_category": experience_category,
        "experience_years": experience_years
    }

    return structured_vacancy

def read_txt(file):
    """–ß—Ç–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —á–µ—Ä–µ–∑ Streamlit."""
    return file.read().decode('utf-8')


def process_vacancy(vacancy_text, skills_list):
    career_titles = extract_career_titles(vacancy_text)
    found_locations = extract_locations(vacancy_text)
    extracted_skills = extract_entities_with_skills(vacancy_text, skills_list)
    cleaned_skills = clean_skills(extracted_skills['SKILLS'], skills_list)
    final_skills = final_clean_skills(cleaned_skills, important_short_skills)
    experience_category, experience_years = extract_experience_category_and_years(vacancy_text)

    structured_vacancy = {
        "skills": final_skills if final_skills else None,
        "locations": list(found_locations) if found_locations else None,
        "career_titles": list(career_titles) if career_titles else None,
        "experience_category": experience_category,
        "experience_years": experience_years
    }
    
    return structured_vacancy

def generate_resume_recommendations(structured_resume: dict) -> list:
    recommendations = []

    if not structured_resume.get("has_photo"):
        recommendations.append("üì∑ –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–±–∞–≤–∏—Ç—å —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é –≤ —Ä–µ–∑—é–º–µ ‚Äî —ç—Ç–æ –º–æ–∂–µ—Ç –ø–æ–≤—ã—Å–∏—Ç—å –¥–æ–≤–µ—Ä–∏–µ —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—è.")

    if not structured_resume.get("name"):
        recommendations.append("üìù –î–æ–±–∞–≤—å—Ç–µ —Å–≤–æ—ë –∏–º—è –≤ –Ω–∞—á–∞–ª–µ —Ä–µ–∑—é–º–µ –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏.")

    if not structured_resume.get("email"):
        recommendations.append("üìß –£–∫–∞–∂–∏—Ç–µ —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—É—é –ø–æ—á—Ç—É –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏.")

    if not structured_resume.get("phone"):
        recommendations.append("üìû –£–∫–∞–∂–∏—Ç–µ –Ω–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞ –¥–ª—è –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–π —Å–≤—è–∑–∏.")

    if not structured_resume.get("skills"):
        recommendations.append("üõ†Ô∏è –ó–∞–ø–æ–ª–Ω–∏—Ç–µ —Ä–∞–∑–¥–µ–ª '–ù–∞–≤—ã–∫–∏', —á—Ç–æ–±—ã –ø–æ–¥—á–µ—Ä–∫–Ω—É—Ç—å —Å–≤–æ–∏ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏.")

    if not structured_resume.get("education"):
        recommendations.append("üéì –£–∫–∞–∂–∏—Ç–µ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ, –æ—Å–æ–±–µ–Ω–Ω–æ –µ—Å–ª–∏ –æ–Ω–æ –ø—Ä–æ—Ñ–∏–ª—å–Ω–æ–µ.")

    if not structured_resume.get("career_titles"):
        recommendations.append("üè∑Ô∏è –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–∫–∞–∑–∞—Ç—å –¥–æ–ª–∂–Ω–æ—Å—Ç–∏/—Ä–æ–ª–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã –∑–∞–Ω–∏–º–∞–ª–∏.")

    if structured_resume.get("experience_years") is None:
        recommendations.append("‚åõ –î–æ–±–∞–≤—å—Ç–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–≤–æ—ë–º –æ–ø—ã—Ç–µ —Ä–∞–±–æ—Ç—ã.")

    return recommendations


def compare_resume_to_vacancy(resume_data, vacancy_data):
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–∞–≤—ã–∫–æ–≤, –æ–ø—ã—Ç–∞ –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ —Ä–µ–∑—é–º–µ –∏ –≤–∞–∫–∞–Ω—Å–∏–∏."""
    result = {}

    resume_skills = set(resume_data.get('skills', []))
    vacancy_skills = set(vacancy_data.get('skills', []))

    matched_skills = resume_skills.intersection(vacancy_skills)
    unmatched_skills = vacancy_skills.difference(resume_skills)

    skill_match_percent = (len(matched_skills) / len(vacancy_skills)) * 100 if vacancy_skills else 0

    result['matched_skills'] = list(matched_skills)
    result['unmatched_skills'] = list(unmatched_skills)
    result['skill_match_percent'] = round(skill_match_percent, 2)

    resume_experience = resume_data.get('experience_years')
    vacancy_experience = vacancy_data.get('experience_years')

    if resume_experience is not None and vacancy_experience is not None:
        experience_ok = resume_experience >= vacancy_experience
    else:
        experience_ok = None

    result['experience_match'] = experience_ok
    result['resume_experience_years'] = resume_experience
    result['vacancy_experience_years'] = vacancy_experience

    resume_titles = set(resume_data.get('career_titles') or [])
    vacancy_titles = set(vacancy_data.get('career_titles') or [])

    title_match = bool(resume_titles.intersection(vacancy_titles))

    result['career_title_match'] = title_match

    return result

def calculate_tfidf_similarity(text1, text2):
    """–†–∞—Å—á–µ—Ç TF-IDF cosine similarity –º–µ–∂–¥—É –¥–≤—É–º—è —Ç–µ–∫—Å—Ç–∞–º–∏."""
    vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(3, 5))
    tfidf_matrix = vectorizer.fit_transform([text1, text2])
    similarity = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]
    return round(similarity, 4)

def calculate_combined_similarity(skill_match_percent: float, tfidf_similarity: float,
                                   weight_skills: float = 0.6, weight_tfidf: float = 0.4) -> float:
    """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–µ—Ç—Ä–∏–∫—É Similarity –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–≤—ã–∫–æ–≤ –∏ TF-IDF."""
    skill_match_score = skill_match_percent / 100  # –ø–µ—Ä–µ–≤–æ–¥–∏–º –ø—Ä–æ—Ü–µ–Ω—Ç –≤ [0,1]
    combined_score = (skill_match_score * weight_skills) + (tfidf_similarity * weight_tfidf)
    return round(combined_score, 4)
def generate_roadmap_for_profession(profession, user_experience, user_skills, G):
    roadmap = {"–ù–∞—á–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å": [], "–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å": [], "–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —É—Ä–æ–≤–µ–Ω—å": []}
    if profession not in G:
        return roadmap

    for neighbor in G.neighbors(profession):
        node_data = G.nodes[neighbor]
        node_type = node_data.get('type')
        importance = node_data.get('weight', 0)
        experience_required = node_data.get('experience_category', '–ù–µ—Ç –æ–ø—ã—Ç–∞')

        if node_type not in ["skill", "education", "experience"]:
            continue

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å
        if experience_required == "–ù–µ—Ç –æ–ø—ã—Ç–∞":
            level = "–ù–∞—á–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å"
        elif experience_required in ["1-3 –≥–æ–¥–∞"]:
            level = "–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å"
        else:
            level = "–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —É—Ä–æ–≤–µ–Ω—å"

        roadmap[level].append({
            "–Ω–∞–∑–≤–∞–Ω–∏–µ": neighbor,
            "—Ç–∏–ø": node_type,
            "–≤–∞–∂–Ω–æ—Å—Ç—å": importance,
            "—É–∂–µ_–µ—Å—Ç—å": neighbor in user_skills
        })

    for level in roadmap:
        roadmap[level] = sorted(roadmap[level], key=lambda x: -x["–≤–∞–∂–Ω–æ—Å—Ç—å"])
    return roadmap
